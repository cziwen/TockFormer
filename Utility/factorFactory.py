import pandas as pd
import numpy as np
import math
import matplotlib.pyplot as plt
from typing import List, Optional, Dict, Any
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
from tqdm import tqdm
from scipy.stats import spearmanr
from sklearn.decomposition import PCA
from sklearn.manifold import LocallyLinearEmbedding, TSNE
from mpi4py import MPI

from Utility.registry import FACTOR_REGISTRY
from Utility.factors import *


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ operator functions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def mul_func (x, y):    return x * y


def minus_func (x, y):  return x - y


def div_func (x, y):    return x.div (y.replace (0, pd.NA))


def sin_func (x):       return x.map (math.sin)


def cos_func (x):       return x.map (math.cos)


CROSS_OPS = [
    {'name': 'mul', 'arity': 2, 'func': mul_func, 'preserves_bounded': True},
    {'name': 'minus', 'arity': 2, 'func': minus_func, 'preserves_bounded': True},
    {'name': 'div', 'arity': 2, 'func': div_func, 'preserves_bounded': False},
    {'name': 'sin', 'arity': 1, 'func': sin_func, 'preserves_bounded': True},
    {'name': 'cos', 'arity': 1, 'func': cos_func, 'preserves_bounded': True},
]


def _cross_apply (args):
    op, a, b, data_dict = args
    name = f"{a}_{op['name']}_{b}"
    return name, op['func'] (data_dict[a], data_dict[b])


class FactorFactory:
    def __init__ (
            self,
            df: pd.DataFrame,
            base_cols: Optional[List[str]] = None,
            target_col: str = 'close',
            forward_period: int = 1,
            window: int = 20,
            scaler: str = 'minmax',
            top_k: Optional[int] = None,
            decimals: int = 4
    ):
        # åŸå§‹æ•°æ®æŒ‰ timestamp ç´¢å¼•
        self.df_global = (
            df.copy ()
            .sort_values ('timestamp')
            .set_index ('timestamp')
        )
        self.base_cols = (
            base_cols if base_cols is not None
            else [c for c in self.df_global.select_dtypes (include=[np.number]).columns]
        )
        self.target_col = target_col
        self._eval_kwargs = dict (
            forward_period=forward_period,
            window=window,
            scaler=scaler,
            top_k=top_k
        )
        self.decimals = decimals
        self.df_features = pd.DataFrame ()
        self.summary = pd.DataFrame ()

    def apply_registry (
            self,
            df: pd.DataFrame,
            bounded_only: bool = False
    ) -> pd.DataFrame:
        """
        å¯¹ä¼ å…¥çš„ dfï¼ˆå¿…é¡»æœ‰ timestamp ç´¢å¼•ï¼‰æŒ‰åˆ—ä¾æ¬¡æ‰§è¡Œ FACTOR_REGISTRY
        ä¸­æ³¨å†Œçš„æ‰€æœ‰ funcï¼Œè¿”å›ä¸€ä¸ª new_feats DataFrameã€‚
        bounded_only=True æ—¶ï¼Œè·³è¿‡é 'bounded' å› å­ã€‚
        """
        # å¤‡ä»½åŸå±æ€§
        orig_df = self.df_global
        orig_base = self.base_cols
        orig_target = self.target_col

        # ä¸´æ—¶æ›¿æ¢
        self.df_global = df.copy ()
        self.base_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype (df[c])]
        self.target_col = self.target_col if self.target_col in df.columns else None

        new_feats: Dict[str, pd.Series] = {}
        for info in FACTOR_REGISTRY.values ():
            tags = info.get ('tags', [])
            if bounded_only and 'bounded' not in tags:
                continue

            out = info['func'] (self)
            # å¤„ç†è¿”å›
            if isinstance (out, pd.Series):
                col = out.name or info.get ('name', 'unnamed_factor')
                out = out.rename (col)
                new_feats[col] = out
            else:
                for name, series in out.items ():
                    new_feats[name] = pd.Series (series, index=df.index, name=name)

        # æ¢å¤åŸå±æ€§
        self.df_global = orig_df
        self.base_cols = orig_base
        self.target_col = orig_target

        return pd.DataFrame (new_feats, index=df.index)

    def generate_factors (
            self,
            mode: str = 'single',
            n_job: Optional[int] = None,
            bounded_only: bool = False
    ) -> pd.DataFrame:
        # 1) å…ˆç”¨æ³¨å†Œè¡¨ç”Ÿæˆä¸€é˜¶å› å­
        feat_df = self.apply_registry (self.df_global, bounded_only=bounded_only)
        feat_df.index.name = 'timestamp'

        # 2) å†åšäº¤å‰è¿ç®—
        cross_df = self.cross_op (feat_df, mode, n_job, bounded_only)

        # 3) åˆå¹¶ã€å»å¸¸æ•°/NaN
        merged = pd.concat ([feat_df, cross_df], axis=1)
        drop_cols = merged.nunique ()[merged.nunique () <= 1].index.tolist ()
        df_feat = merged.drop (columns=drop_cols).dropna ()

        # 4) reset_index å¹¶è¯„ä¼°
        self.df_features = df_feat.reset_index ().round (self.decimals)
        self.evaluate_factors (**self._eval_kwargs)
        return self.df_features

    def cross_op (
            self,
            input_df: pd.DataFrame,
            mode: str = 'single',
            n_job: Optional[int] = None,
            bounded_only: bool = False
    ) -> pd.DataFrame:
        data = input_df.copy ()
        feats: Dict[str, pd.Series] = {}

        # â€”â€” æ–°å¢ï¼šå…ˆè·‘æ³¨å†Œè¡¨ â€”â€”
        reg_df = self.apply_registry (data, bounded_only=bounded_only)
        feats.update (reg_df.to_dict ('series'))

        # â€”â€” ä¸€å…ƒç®—å­ â€”â€”
        for col in data.columns:
            for op in CROSS_OPS:
                if op['arity'] == 1 and (not bounded_only or op['preserves_bounded']):
                    feats[f"{op['name']}_{col}"] = op['func'] (data[col])

        # â€”â€” äºŒå…ƒç®—å­æ„é€ ä»»åŠ¡åˆ—è¡¨ â€”â€”
        dd = data.to_dict ('series')
        tasks = [
            (op, a, b, dd)
            for op in CROSS_OPS
            if op['arity'] == 2 and (not bounded_only or op['preserves_bounded'])
            for a in data.columns for b in data.columns
        ]

        # å¹¶è¡Œæˆ–ä¸²è¡Œæ‰§è¡Œ
        if mode == 'mpi':
            comm = MPI.COMM_WORLD
            size, rank = comm.Get_size (), comm.Get_rank ()
            local = [t for i, t in enumerate (tasks) if i % size == rank]
            local_res = dict (_cross_apply (t) for t in local)
            all_res = comm.gather (local_res, root=0)
            if rank == 0:
                merged = {}
                for d in all_res: merged.update (d)
                feats.update (merged)
            comm.Barrier ()

        elif mode == 'process':
            with ProcessPoolExecutor (max_workers=n_job) as exe:
                for name, series in tqdm (exe.map (_cross_apply, tasks),
                                          total=len (tasks), desc="ğŸ”„ cross_op (proc)"):
                    feats[name] = series

        elif mode == 'thread':
            with ThreadPoolExecutor (max_workers=n_job) as exe:
                for name, series in tqdm (exe.map (_cross_apply, tasks),
                                          total=len (tasks), desc="ğŸ”„ cross_op (thread)"):
                    feats[name] = series

        else:  # single
            for t in tqdm (tasks, total=len (tasks), desc="ğŸ”„ cross_op (single)"):
                name, series = _cross_apply (t)
                feats[name] = series

        # æ„é€  DataFrame å¹¶å¯¹é½
        df_new = pd.DataFrame (feats).reindex (data.index)
        df_new.index.name = 'timestamp'
        return df_new

    def evaluate_factors (
            self,
            forward_period: int,
            window: int,
            scaler: str = 'minmax',
            top_k: Optional[int] = None
    ) -> pd.DataFrame:
        # å¯¹é½ç´¢å¼•
        df = self.df_features.set_index ('timestamp')
        price = self.df_global[self.target_col]
        returns = price.shift (-forward_period) / price - 1
        df_eval = df.join (returns.rename ('forward_return')).dropna ()

        # å¦‚æœæ•°æ®è¡Œå°‘äºçª—å£ï¼Œåˆ™è‡ªåŠ¨ç¼©å°çª—å£
        win_eff = min (window, max (1, len (df_eval) - 1))

        # 1) æ”¶é›† Spearman IC å’Œ IR
        stats: Dict[str, Dict[str, float]] = {}
        for col in df_eval.columns.drop ('forward_return'):
            # åŸå§‹ Spearman IC å¯èƒ½æ˜¯ numpy scalar æˆ– array
            raw_sp = spearmanr (df_eval[col], df_eval['forward_return']).correlation
            # å¼ºåˆ¶å–ç¬¬ä¸€ä¸ªå…ƒç´ ï¼Œä¿è¯æ ‡é‡
            sp = float (np.atleast_1d (raw_sp).ravel ()[0])

            roll = df_eval[col].rolling (win_eff).corr (df_eval['forward_return'])
            arr = roll.values
            valid = arr[~np.isnan (arr)]
            if valid.size == 0:
                ir_raw = np.nan
            else:
                pm = valid.mean ()
                ps = valid.std (ddof=0)
                ir_raw = pm / ps if ps != 0 else np.nan
            # åŒæ ·å¼ºåˆ¶é™ç»´
            ir = float (np.atleast_1d (ir_raw).ravel ()[0])

            stats[col] = {'spearman_ic': sp, 'pearson_ir': ir}

        # 2) è®¡ç®— PCA è½½è·å¹¶æ›´æ–°
        feats = list (stats.keys ())
        X_sub = (df[feats] - df[feats].mean ()) / df[feats].std ()
        pca = PCA (n_components=1);
        pca.fit (X_sub)
        loadings = np.abs (pca.components_[0])
        for f, ld in zip (feats, loadings):
            stats[f]['pca_coeff'] = float (ld)

        # 3) æ„å»º summary
        summary = pd.DataFrame.from_dict (stats, orient='index')

        # â€”â€” å¼ºåˆ¶è½¬æµ®ç‚¹ï¼Œé˜²æ­¢åç»­éæ•°å€¼ dtype æŠ¥é”™ â€”â€”
        for m in ['spearman_ic', 'pearson_ir', 'pca_coeff']:
            summary[m] = pd.to_numeric (summary[m], errors='coerce')

        # 4) å½’ä¸€åŒ– & åˆæˆ
        for m in ['spearman_ic', 'pearson_ir', 'pca_coeff']:
            arr = summary[m].dropna ().to_numpy (dtype=float)
            if arr.size == 0:
                summary[f'{m}_norm'] = np.nan
                continue

            if scaler == 'minmax':
                mi, ma = arr.min (), arr.max ()
                if ma == mi:
                    summary[f'{m}_norm'] = 0.0
                else:
                    summary[f'{m}_norm'] = (summary[m] - mi) / (ma - mi)
            else:  # z-score
                mu, sd = arr.mean (), arr.std (ddof=0)
                if sd == 0:
                    summary[f'{m}_norm'] = 0.0
                else:
                    summary[f'{m}_norm'] = (summary[m] - mu) / sd

        # 5) åˆæˆæœ€ç»ˆå¾—åˆ†
        summary['combined_score'] = (
                summary['spearman_ic_norm']
                + summary['pearson_ir_norm']
                + summary['pca_coeff_norm']
        )

        # 6) æ’åºå¹¶é€‰ top_k
        summary = summary.sort_values ('combined_score', ascending=False)
        if top_k:
            summary = summary.head (top_k)

        # ä¿ç•™å°æ•°
        summary = summary.round (self.decimals)

        self.summary = summary
        return summary

    def get_summary (self, sort_by='combined_score', ascending=False) -> pd.DataFrame:
        return self.summary.sort_values (sort_by, ascending=ascending)

    def next (
            self,
            steps: int = 1,
            k: int = 1,
            mode: str = 'single',
            n_job: Optional[int] = None,
            bounded_only: bool = False
    ) -> pd.DataFrame:
        for _ in tqdm (range (steps), desc="ğŸ”„ next steps"):
            features = list (self.summary.index)
            mat = self.df_features.set_index ('timestamp')[features].values
            corr = np.abs (np.corrcoef (mat.T))
            idx_map = {f: i for i, f in enumerate (features)}

            kept = [features.pop (0)]
            while len (kept) < k and features:
                max_corrs = [
                    max (corr[idx_map[f], idx_map[kf]] for kf in kept)
                    for f in features
                ]
                pos = int (np.argmin (max_corrs))
                kept.append (features.pop (pos))

            sub_df = self.df_features.set_index ('timestamp')[kept]
            newf = self.cross_op (sub_df, mode, n_job, bounded_only)
            merged = pd.concat ([sub_df, newf], axis=1)
            drop_cols = merged.nunique ()[merged.nunique () <= 1].index.tolist ()
            merged = merged.drop (columns=drop_cols).dropna ()

            self.df_features = merged.reset_index ()
            self.df_features = self.df_features.round (self.decimals)
            self.evaluate_factors (**self._eval_kwargs)

        return self.df_features

    def visualize_structure_2d (
            self,
            seq_len: int,
            perplexity: float = 30.0,
            n_neighbors: int = 10,
            random_state: int = 42
    ) -> None:
        """
        ä¸€æ¬¡æ€§ç»˜åˆ¶ 4 ç§äºŒç»´é™ç»´æ•£ç‚¹å›¾ï¼ŒæŒ‰ self.target_col çš„å‰å‘æ¶¨è·Œç€è‰²ã€‚
        è¿›åº¦æ¡è¦†ç›–æ»‘çª—å±•å¼€å’Œå„ç®—æ³•é™ç»´ä¸¤ä¸ªé˜¶æ®µã€‚

        å‚æ•°ï¼š
          - seq_len:      æ»‘çª—é•¿åº¦ï¼›
          - perplexity:   t-SNE çš„ perplexityï¼›
          - n_neighbors:  LLE çš„é‚»å±…æ•°é‡ï¼›
          - random_state: éšæœºç§å­ã€‚
        """

        # â€”â€”â€” 1. æå–å·²ç”Ÿæˆçš„ç‰¹å¾çŸ©é˜µ & æ—¶é—´ç´¢å¼• â€”â€”â€”
        df_feat = self.df_features.copy ()
        timestamps = df_feat['timestamp']
        X = df_feat.drop (columns=['timestamp']).values  # (T, d)
        T, d = X.shape

        # â€”â€”â€” 2. è®¡ç®—å‰å‘æ”¶ç›Š & å¯¹é½æ ‡ç­¾ â€”â€”â€”
        fp = self._eval_kwargs['forward_period']
        forward_ret = (
                self.df_global[self.target_col].shift (-fp)
                / self.df_global[self.target_col]
                - 1
        )
        aligned_forward = forward_ret.reindex (timestamps).reset_index (drop=True)

        # â€”â€”â€” 3. æ»‘çª—å±•å¼€ & æ ‡å‡†åŒ–ï¼ˆå¸¦è¿›åº¦æ¡ï¼‰ â€”â€”â€”
        N = T - seq_len + 1
        V = np.empty ((N, seq_len * d), dtype=float)
        for i in tqdm (range (N), desc="ğŸ”„ çª—å£å±•å¹³"):
            V[i, :] = X[i:i + seq_len, :].flatten ()
        V = (V - V.mean (axis=0)) / (V.std (axis=0, ddof=0) + 1e-8)

        # â€”â€”â€” 4. ç”Ÿæˆæ¶¨è·Œæ ‡ç­¾ â€”â€”â€”
        labels = (aligned_forward.iloc[seq_len - 1: seq_len - 1 + N] >= 0).astype (int).to_numpy ()

        # â€”â€”â€” 5. å››ç§é™ç»´æ–¹æ³•ï¼ˆå¸¦è¿›åº¦æ¡ï¼‰ â€”â€”â€”
        reducers = [
            ('PCA-2', PCA (n_components=2, random_state=random_state)),
            ('LLE', LocallyLinearEmbedding (
                n_neighbors=n_neighbors,
                n_components=2,
                random_state=random_state)),
            ('t-SNE', TSNE (
                n_components=2,
                perplexity=perplexity,
                random_state=random_state)),
            # è¿™é‡Œç›´æ¥å­˜ä¸€ä¸ª floatï¼Œè¡¨ç¤ºã€Œä¿ç•™ 90%ã€çš„é˜ˆå€¼
            ('PCA(90%)â†’t-SNE', 0.90)
        ]
        results = {}
        for name, algo in tqdm (reducers, desc="ğŸ”„ é™ç»´ç®—æ³•"):
            if name == 'PCA(90%)â†’t-SNE':
                # å…ˆ PCA ä¿ç•™ 90%ï¼Œå† t-SNE
                V_pca90 = PCA (n_components=algo, random_state=random_state).fit_transform (V)
                Z = TSNE (n_components=2, perplexity=perplexity, random_state=random_state).fit_transform (V_pca90)
            else:
                Z = algo.fit_transform (V)
            results[name] = Z

        # â€”â€”â€” 6. ç»˜å›¾ï¼ˆä½¿ç”¨ constrained_layoutï¼‰ â€”â€”â€”
        fig, axes = plt.subplots (
            2, 2,
            figsize=(12, 10),
            constrained_layout=True
        )
        cm = plt.cm.coolwarm

        for ax, (title, Z) in zip (axes.flatten (), results.items ()):
            sc = ax.scatter (
                Z[:, 0], Z[:, 1],
                c=labels,
                cmap=cm,
                s=10,
                alpha=0.7
            )
            ax.set_title (title, fontsize=12)
            ax.set_xlabel ('Component 1')
            ax.set_ylabel ('Component 2')

        cbar = fig.colorbar (sc, ax=axes.ravel ().tolist (), ticks=[0, 1])
        cbar.ax.set_yticklabels (['Down', 'Up'])

        fig.suptitle (f'2D Structure Visualization (seq_len={seq_len})', fontsize=14)
        plt.show ()
