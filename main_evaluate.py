# import argparse
# import os
# import torch
# import joblib
# import pandas as pd
# import numpy as np
# from torch.utils.data import TensorDataset
#
# from TransformerModel import TimeSeriesTransformer
# from Util import create_sequences, plot_multiple_curves, safeLoadCSV
#
#
# def evaluate_model_main(test_csv, model_path, scaler_path,
#                         batch_size=32, seq_length=32,
#                         input_dim=33, model_dim=64, num_heads=4, num_layers=2,
#                         output_dim=4, dropout=0.2):
#
#     print("=" * 10 + " åŠ è½½æ¨¡å‹å’Œ Scaler... " + "=" * 10)
#     model = TimeSeriesTransformer(
#         input_dim=input_dim,
#         model_dim=model_dim,
#         num_heads=num_heads,
#         num_layers=num_layers,
#         dropout=dropout,
#         seq_length=seq_length,
#         output_dim=output_dim
#     )
#
#     device = torch.device ("cuda" if torch.cuda.is_available () else "cpu")
#     model.load_state_dict (torch.load (model_path, map_location=device))
#     model.to (device)
#     scaler = joblib.load(scaler_path)
#
#     print("=" * 10 + " åŠ è½½æµ‹è¯•æ•°æ®... " + "=" * 10)
#     test_df = safeLoadCSV(pd.read_csv(test_csv))
#     x_test, y_test, _, target_indices = create_sequences(
#         test_df, seq_length=seq_length, scaler=scaler,
#         target_cols=['open', 'high', 'low', 'close']
#     )
#     test_dataset = TensorDataset(x_test, y_test)
#
#     print("=" * 10 + " å¼€å§‹è¯„ä¼°æ¨¡å‹... " + "=" * 10)
#     mse_list, r2_list, preds, actuals = model.evaluate_model(
#         test_dataset,
#         batch_size=batch_size,
#         scaler=scaler,
#         target_indices=target_indices
#     )
#
#     print("=" * 10 + " è¯„ä¼°å®Œæˆ... " + "=" * 10)
#     print(f"ğŸ“‰ MSE: {mse_list}")
#     print(f"ğŸ“ˆ RÂ² : {r2_list}")
#
#     # å¯è§†åŒ–é¢„æµ‹ç»“æœï¼ˆæ”¶ç›˜ä»·ï¼‰
#     curve_dict = {
#         'Close_pred': preds[:, 3],
#         'Close_actual': actuals[:, 3]
#     }
#     plot_multiple_curves(
#         curve_dict,
#         x_label='interval',
#         y_label='price',
#         title='Close Comparison'
#     )
#
#
# if __name__ == "__main__":
#     parser = argparse.ArgumentParser(description="åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼° Transformer æ¨¡å‹æ€§èƒ½")
#     parser.add_argument('--test', type=str, required=True, help='æµ‹è¯•æ•°æ® CSV è·¯å¾„')
#     parser.add_argument('--model', type=str, required=True, help='æ¨¡å‹æ–‡ä»¶è·¯å¾„ï¼ˆ.pthï¼‰')
#     parser.add_argument('--scaler', type=str, required=True, help='Scaler æ–‡ä»¶è·¯å¾„ï¼ˆ.pklï¼‰')
#     parser.add_argument('--batch_size', type=int, default=32, help='æ‰¹å¤§å°')
#     parser.add_argument ('--sequential_length', type=int, default=32, help='åºåˆ—é•¿åº¦')
#     parser.add_argument ("--input_dim", type=int, required=True, help="æ¨¡å‹è¾“å…¥ç»´åº¦")
#     parser.add_argument ("--output_dim", type=int, required=True, help="æ¨¡å‹è¾“å‡ºç»´åº¦")
#     parser.add_argument ("--num_layers", type=int, required=True, help="æ¨¡å‹å±‚æ•°")
#     parser.add_argument ("--num_heads", type=int, required=True, help="æ³¨æ„åŠ›å¤´æ•°")
#     parser.add_argument ("--dropout", type=float, default=0.2, help="Dropout")
#
#
#
#     args = parser.parse_args()
#
#     evaluate_model_main(
#         test_csv=args.test,
#         model_path=args.model,
#         scaler_path=args.scaler,
#         batch_size=args.batch_size,
#         seq_length=args.sequential_length,
#         input_dim=args.input_dim,
#         output_dim=args.output_dim,
#         num_layers=args.num_layers,
#         num_heads=args.num_heads,
#         dropout=args.dropout
#     )

import argparse
import os
import numpy as np
import pandas as pd
import torch
from torch.utils.data import TensorDataset
import joblib

from TransformerModel import TimeSeriesTransformer
from TransformerModel_classify import TimeSeriesTransformer_classify
from Util import create_sequences, safeLoadCSV, plot_metric, plot_multiple_curves


def evaluate_model_regression_main(test_csv, model_path, scaler_path, batch_size=32, seq_length=32,
                                   input_dim=33, model_dim=64, output_dim=4, num_layers=2,
                                   num_heads=4, dropout=0.2):
    """
    å›å½’ä»»åŠ¡è¯„ä¼°å‡½æ•°ï¼š
    - åŠ è½½æµ‹è¯•æ•°æ®ï¼ˆå‡è®¾ç›®æ ‡åˆ—ä¸º ['open', 'high', 'low', 'close']ï¼‰
    - ä½¿ç”¨ scaler å¯¹æ¨¡å‹é¢„æµ‹ç»“æœé€†ç¼©æ”¾ï¼Œå¹¶è®¡ç®— MSE å’Œ RÂ² æŒ‡æ ‡
    """
    print("=" * 10 + " åŠ è½½å›å½’ä»»åŠ¡æµ‹è¯•æ•°æ®ä¸­... " + "=" * 10)
    test_df = pd.read_csv(test_csv)
    scaler = joblib.load (scaler_path)
    # æ³¨æ„ï¼šè¿™é‡Œç›®æ ‡åˆ—ä¸ºå›å½’ä»»åŠ¡çš„ç›®æ ‡ï¼Œåç§°å¯æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´
    x_test, y_test, _, target_indices = create_sequences(test_df, seq_length=seq_length,
                                                              target_cols=['open', 'high', 'low', 'close'], scaler=scaler)
    test_dataset = TensorDataset(x_test, y_test)

    print("=" * 10 + " æ„é€ å›å½’æ¨¡å‹å¹¶åŠ è½½å‚æ•°... " + "=" * 10)
    model = TimeSeriesTransformer(
        input_dim=input_dim,
        model_dim=model_dim,
        num_heads=num_heads,
        num_layers=num_layers,
        dropout=dropout,
        seq_length=seq_length,
        output_dim=output_dim
    )

    device = torch.device ("cuda" if torch.cuda.is_available () else "cpu")
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.eval()

    # ä½¿ç”¨å›å½’è¯„ä¼°å‡½æ•°ï¼Œè¿”å› MSEã€RÂ² ç­‰æŒ‡æ ‡
    mse_list, r2_list, preds, targets = model.evaluate_model(test_dataset, batch_size=batch_size,
                                                              scaler=scaler, target_indices=target_indices)
    print("æµ‹è¯•é›† MSE: ", mse_list)
    print("æµ‹è¯•é›† RÂ²: ", r2_list)


    curve_dict = {}
    curve_dict['predicts'] = preds[:, 3]
    curve_dict['targets'] = targets[:, 3]
    plot_multiple_curves(curve_dict, x_label= 'interval', y_label= 'price')


def evaluate_model_classification_main(test_csv, model_path, batch_size=32, seq_length=32,
                                       input_dim=33, model_dim=64, output_dim=3, num_layers=2,
                                       num_heads=4, dropout=0.2):
    """
    åˆ†ç±»ä»»åŠ¡è¯„ä¼°å‡½æ•°ï¼š
    - åŠ è½½æµ‹è¯•æ•°æ®ï¼ˆå‡è®¾ç›®æ ‡åˆ—ä¸º 'label'ï¼Œæ ‡ç­¾ä¸ºæ•´æ•°ï¼‰
    - ç›´æ¥è®¡ç®—åˆ†ç±»å‡†ç¡®ç‡
    """
    print("=" * 10 + " åŠ è½½åˆ†ç±»ä»»åŠ¡æµ‹è¯•æ•°æ®ä¸­... " + "=" * 10)
    test_df = pd.read_csv(test_csv)
    # ä¿®æ”¹ç‚¹ï¼šé’ˆå¯¹åˆ†ç±»ä»»åŠ¡ï¼Œå‡è®¾ç›®æ ‡åˆ—åç§°ä¸º 'label'
    x_test, y_test, _, _ = create_sequences(test_df, seq_length=seq_length,
                                            target_cols=['label'])
    # å°†æ ‡ç­¾è½¬æ¢ä¸º LongTensor ä»¥é€‚ç”¨äº CrossEntropyLoss
    # y_test = y_test.long()
    test_dataset = TensorDataset(x_test, y_test)

    print("=" * 10 + " æ„é€ åˆ†ç±»æ¨¡å‹å¹¶åŠ è½½å‚æ•°... " + "=" * 10)
    model = TimeSeriesTransformer_classify(
        input_dim=input_dim,
        model_dim=model_dim,
        num_heads=num_heads,
        num_layers=num_layers,
        dropout=dropout,
        seq_length=seq_length,
        output_dim=output_dim  # output_dim è¡¨ç¤ºç±»åˆ«æ•°
    )

    device = torch.device ("cuda" if torch.cuda.is_available () else "cpu")
    model.load_state_dict (torch.load (model_path, map_location=device))
    model.eval ()


    # ä½¿ç”¨åˆ†ç±»è¯„ä¼°å‡½æ•°ï¼Œè¿”å›å‡†ç¡®ç‡
    accuracy = model.evaluate_model(test_dataset, batch_size=batch_size)
    print("æµ‹è¯•é›†å‡†ç¡®ç‡: {:.4f}".format(accuracy))



if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼° Transformer æ¨¡å‹æ€§èƒ½")
    # æ–°å¢ --task å‚æ•°ï¼Œç”¨äºåŒºåˆ†å›å½’å’Œåˆ†ç±»ä»»åŠ¡
    parser.add_argument("--task", type=str, default="regression", choices=["regression", "classification"],
                        help="ä»»åŠ¡ç±»å‹ï¼šå›å½’æˆ–åˆ†ç±»")
    parser.add_argument('--test', type=str, required=True, help='æµ‹è¯•æ•°æ® CSV è·¯å¾„')
    parser.add_argument('--model', type=str, required=True, help='æ¨¡å‹æ–‡ä»¶è·¯å¾„ï¼ˆ.pthï¼‰')
    # å¯¹äºå›å½’ä»»åŠ¡éœ€è¦ scaler æ–‡ä»¶ï¼Œåˆ†ç±»ä»»åŠ¡ä¸éœ€è¦
    parser.add_argument('--scaler', type=str, help='Scaler æ–‡ä»¶è·¯å¾„ï¼ˆ.pklï¼‰ï¼Œä»…å›å½’ä»»åŠ¡ä½¿ç”¨')
    parser.add_argument('--batch_size', type=int, default=32, help='æ‰¹å¤§å°')
    parser.add_argument('--sequential_length', type=int, default=32, help='åºåˆ—é•¿åº¦')
    parser.add_argument("--input_dim", type=int, required=True, help="æ¨¡å‹è¾“å…¥ç»´åº¦")
    parser.add_argument("--output_dim", type=int, required=True, help="æ¨¡å‹è¾“å‡ºç»´åº¦ï¼ˆå›å½’ï¼šç›®æ ‡æ•°ï¼›åˆ†ç±»ï¼šç±»åˆ«æ•°ï¼‰")
    # æ–°å¢æ¨¡å‹æ˜ å°„ç»´åº¦å‚æ•°ï¼Œä¿è¯ä¸æ¨¡å‹ç»“æ„ä¸€è‡´
    parser.add_argument("--model_dim", type=int, required=True, help="æ¨¡å‹æ˜ å°„ç»´åº¦")
    parser.add_argument("--num_layers", type=int, required=True, help="æ¨¡å‹å±‚æ•°")
    parser.add_argument("--num_heads", type=int, required=True, help="æ³¨æ„åŠ›å¤´æ•°")
    parser.add_argument("--dropout", type=float, default=0.2, help="Dropout")

    args = parser.parse_args()

    if args.task == "regression":
        if args.scaler is None:
            raise ValueError("å›å½’ä»»åŠ¡å¿…é¡»æä¾› --scaler å‚æ•°")
        evaluate_model_regression_main(
            test_csv=args.test,
            model_path=args.model,
            scaler_path=args.scaler,
            batch_size=args.batch_size,
            seq_length=args.sequential_length,
            input_dim=args.input_dim,
            model_dim=args.model_dim,
            output_dim=args.output_dim,
            num_layers=args.num_layers,
            num_heads=args.num_heads,
            dropout=args.dropout
        )
    elif args.task == "classification":
        evaluate_model_classification_main(
            test_csv=args.test,
            model_path=args.model,
            batch_size=args.batch_size,
            seq_length=args.sequential_length,
            input_dim=args.input_dim,
            model_dim=args.model_dim,
            output_dim=args.output_dim,
            num_layers=args.num_layers,
            num_heads=args.num_heads,
            dropout=args.dropout
        )